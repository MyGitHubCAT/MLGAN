{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import model\n",
    "import func\n",
    "import MLGAN_L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = func.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429831e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dataset_normal,datamean,datastd = func.convertdataset_workday_weekend(env.path)\n",
    "wrkd_dataset,wekd_dataset=func.split_workdayandweekend(st_dataset_normal)\n",
    "adj = func.giveadj(env.adj_csvpath)\n",
    "env.setadj(adj)\n",
    "maskmatrixes = func.Maskmatrixes(env.rmdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the flow data with mask matrixes\n",
    "mmdata = []\n",
    "for i in env.missingrate:    \n",
    "    mmdata.append(maskmatrixes[env.RandNUMS*i:env.RandNUMS*(i+1)])#there are 19 types of mask matrixes based on missing rate\n",
    "    #mmdata.append(maskmatrixes[2*RandNUMS*i:2*RandNUMS*(i+1)])\n",
    "#   \n",
    "mrfordata_data = []\n",
    "dataformr_data = []\n",
    "#we test workday data in this demo\n",
    "origin_dataset = wrkd_dataset[slice(0,int(0.95*len(wrkd_dataset)))]#dataset will be divided into  into train and test data\n",
    "#test_dataset = wrkd_dataset[int(0.95*len(wrkd_dataset)):]\n",
    "for i in mmdata:   \n",
    "    RandNUMS_dataset = origin_dataset\n",
    "    mrfordata = []\n",
    "    dataformr = []\n",
    "    for j in origin_dataset:\n",
    "        for p in i:            \n",
    "            mrfordata.append(p)\n",
    "            dataformr.append(j)\n",
    "    mrfordata_data.append(mrfordata)\n",
    "    dataformr_data.append(dataformr)\n",
    "\n",
    "#convert data into dataset(keras)\n",
    "mmr_datasets = []\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for i in env.missingrate :\n",
    "        mrfordata_dataset =  tf.data.Dataset.from_tensor_slices(np.array(mrfordata_data[i]))\n",
    "        dataformr_dataset =  tf.data.Dataset.from_tensor_slices(np.array(dataformr_data[i]))\n",
    "        mmr_dataset = tf.data.Dataset.zip((dataformr_dataset,mrfordata_dataset)).shuffle(len(mrfordata_data[1])).batch(env.batch_size)\n",
    "        mmr_datasets.append(mmr_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify datasets based on missingrate\n",
    "#5layer model 0-18：0-3，4-7，8-11,12-15,16-18\n",
    "layer1dataforM5 = mmr_datasets[0]\n",
    "for i in mmr_datasets[1:4]:\n",
    "    layer1dataforM5 = layer1dataforM5.concatenate(i)\n",
    "\n",
    "layer2dataforM5 = mmr_datasets[4]\n",
    "for i in mmr_datasets[5:8]:\n",
    "    layer2dataforM5 = layer2dataforM5.concatenate(i)\n",
    "\n",
    "layer3dataforM5 = mmr_datasets[8]\n",
    "for i in mmr_datasets[9:12]:\n",
    "    layer3dataforM5 = layer3dataforM5.concatenate(i)\n",
    "    \n",
    "layer4dataforM5 = mmr_datasets[12]\n",
    "for i in mmr_datasets[13:16]:\n",
    "    layer4dataforM5 = layer4dataforM5.concatenate(i)\n",
    "    \n",
    "layer5dataforM5 = mmr_datasets[16]\n",
    "for i in mmr_datasets[17:]:\n",
    "    layer5dataforM5 = layer5dataforM5.concatenate(i)    \n",
    "    \n",
    "#shuffle to disrupting data\n",
    "layer1dataforM5 = layer1dataforM5.shuffle(buffer_size = len(list(mmr_datasets[0]))*(5+1))\n",
    "layer1dataforM5 = layer1dataforM5.concatenate(layer1dataforM5)\n",
    "layer2dataforM5 = layer2dataforM5.shuffle(buffer_size = len(list(mmr_datasets[0]))*(5+1))\n",
    "layer2dataforM5 = layer2dataforM5.concatenate(layer2dataforM5)\n",
    "layer3dataforM5 = layer3dataforM5.shuffle(buffer_size = len(list(mmr_datasets[0]))*(5+1))\n",
    "layer3dataforM5 = layer3dataforM5.concatenate(layer3dataforM5)\n",
    "layer4dataforM5 = layer4dataforM5.shuffle(buffer_size = len(list(mmr_datasets[0]))*(5+1))\n",
    "layer4dataforM5 = layer4dataforM5.concatenate(layer4dataforM5)\n",
    "layer5dataforM5 = layer5dataforM5.shuffle(buffer_size = len(list(mmr_datasets[0]))*(5+1))\n",
    "layer5dataforM5 = layer5dataforM5.concatenate(layer5dataforM5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50971ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train the MAGAN layer by layer\n",
    "save_path = os.path.join(env.codepath,'MLGAN_Data','modelweight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train the gan module first\n",
    "genlayer1forM5 = model.Layer1MLGAN(288,277)#layer1 model\n",
    "discforM5 =model.MLGANDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.train(genlayer1forM5,discforM5,layer1dataforM5,env.gan_epochs)\n",
    "\n",
    "#Save model parameters in a specific location\n",
    "#genlayer1_path = os.path.join(save_path,'L5GAN','genlayer1forM5','gen_wight')\n",
    "#disclayer1_path = os.path.join(save_path,'L5GAN','disclayer1forM5','disc_wight')\n",
    "#genlayer1forM5.save_weights(genlayer1_path)\n",
    "#discforM5.save_weights(disclayer1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genlayer2forM5 = model.Layer2MLGAN(288,277,fiternums=12,paddingshape=24)#layer2 model\n",
    "\n",
    "#Layer 1 shares parameter information of the input and sampling layers to Layer 2 \n",
    "genlayer2forM5.inherit(genlayer1forM5)\n",
    "genlayer2forM5.Downsampler1.trainable = False\n",
    "genlayer2forM5.Upsampler1.trainable = False\n",
    "#discforM5 =model.MLGANDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.train(genlayer2forM5,discforM5,layer2dataforM5,env.gan_epochs)\n",
    "#genlayer2_path = os.path.join(save_path,'L5GAN','genlayer2forM5','gen_wight')\n",
    "#disclayer2_path = os.path.join(save_path,'L5GAN','disclayer2forM5','disc_wight')\n",
    "#genlayer2forM5.save_weights(genlayer2_path)\n",
    "#discforM5.save_weights(disclayer2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "genlayer3forM5 = model.Layer3MLGAN(288,277,fiternums=12,paddingshape=48)#layer3 model\n",
    "\n",
    "genlayer3forM5.inherit(genlayer2forM5)\n",
    "genlayer3forM5.Downsampler1.trainable = False\n",
    "genlayer3forM5.Upsampler1.trainable = False\n",
    "genlayer3forM5.Downsampler2.trainable = False\n",
    "genlayer3forM5.Upsampler2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb145ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.train(genlayer3forM5,discforM5,layer3dataforM5,env.gan_epochs)\n",
    "#genlayer3_path = os.path.join(save_path,'L5GAN','genlayer3forM5','gen_wight')\n",
    "#disclayer3_path = os.path.join(save_path,'L5GAN','disclayer3forM5','disc_wight')\n",
    "#genlayer3forM5.save_weights(genlayer3_path)\n",
    "#discforM5.save_weights(disclayer3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "genlayer4forM5 = model.Layer4MLGAN(288,277,fiternums=12,paddingshape=72)#layer4 model\n",
    "\n",
    "genlayer4forM5.inherit(genlayer3forM5)\n",
    "genlayer4forM5.Downsampler1.trainable = False\n",
    "genlayer4forM5.Upsampler1.trainable = False\n",
    "genlayer4forM5.Downsampler2.trainable = False\n",
    "genlayer4forM5.Upsampler2.trainable = False\n",
    "genlayer4forM5.Downsampler3.trainable = False\n",
    "genlayer4forM5.Upsampler3.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.train(genlayer4forM5,discforM5,layer4dataforM5,env.gan_epochs)\n",
    "#genlayer4_path = os.path.join(save_path,'L5GAN','genlayer4forM5','gen_wight')\n",
    "#disclayer4_path = os.path.join(save_path,'L5GAN','disclayer4forM5','disc_wight')\n",
    "#genlayer4forM5.save_weights(genlayer4_path)\n",
    "#discforM5.save_weights(disclayer4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a15310",
   "metadata": {},
   "outputs": [],
   "source": [
    "genlayer5forM5 = model.Layer5MLGAN(288,277,fiternums=12,paddingshape=96)#五层模型\n",
    "\n",
    "genlayer5forM5.inherit(genlayer4forM5)\n",
    "genlayer5forM5.Downsampler1.trainable = False\n",
    "genlayer5forM5.Upsampler1.trainable = False\n",
    "genlayer5forM5.Downsampler2.trainable = False\n",
    "genlayer5forM5.Upsampler2.trainable = False\n",
    "genlayer5forM5.Downsampler3.trainable = False\n",
    "genlayer5forM5.Upsampler3.trainable = False\n",
    "genlayer5forM5.Downsampler4.trainable = False\n",
    "genlayer5forM5.Upsampler4.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a719c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.train(genlayer5forM5,discforM5,layer5dataforM5,env.gan_epochs)\n",
    "#genlayer5_path = os.path.join(save_path,'L5GAN','genlayer5forM5','gen_wight')\n",
    "#disclayer5_path = os.path.join(save_path,'L5GAN','disclayer5forM5','disc_wight')\n",
    "#genlayer5forM5.save_weights(genlayer5_path)\n",
    "#discforM5.save_weights(disclayer5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0139cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train the cor module then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train correction layer\n",
    "MLGANcorL1M5 = model.MLGANcorrection(genlayer1forM5)\n",
    "MLGANcorL1M5.gan.trainning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399574d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.trainMLGAN(MLGANcorL1M5,layer1dataforM5,env.cor_epochs)\n",
    "#corlayer1_path = os.path.join(save_path,'L5GAN','corlayer1forM5','cor_wight')\n",
    "#MLGANcorL1M5.save_weights(corlayer1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0776de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLGANcorL2M5 = model.MLGANcorrection(genlayer2forM5)\n",
    "MLGANcorL2M5.gan.trainning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.trainMLGAN(MLGANcorL2M5,layer2dataforM5,env.cor_epochs)\n",
    "#corlayer1_path = os.path.join(save_path,'L5GAN','corlayer1forM5','cor_wight')\n",
    "#MLGANcorL1M5.save_weights(corlayer1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLGANcorL3M5 = model.MLGANcorrection(genlayer3forM5)\n",
    "MLGANcorL3M5.gan.trainning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.trainMLGAN(MLGANcorL3M5,layer3dataforM5,env.cor_epochs)\n",
    "#corlayer3_path = os.path.join(save_path,'L5GAN','corlayer3forM5','cor_wight')\n",
    "#MLGANcorL3M5.save_weights(corlayer3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1214b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLGANcorL4M5 = model.MLGANcorrection(genlayer4forM5)\n",
    "MLGANcorL4M5.gan.trainning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa8987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.trainMLGAN(MLGANcorL4M5,layer4dataforM5,env.cor_epoc)\n",
    "#corlayer4_path = os.path.join(save_path,'L5GAN','corlayer4forM5','cor_wight')\n",
    "#MLGANcorL4M5.save_weights(corlayer4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89309e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLGANcorL5M5 = model.MLGANcorrection(genlayer5forM5)\n",
    "MLGANcorL5M5.gan.trainning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.trainMLGAN(MLGANcorL5M5,layer5dataforM5,env.cor_epoc)\n",
    "#corlaye51_path = os.path.join(save_path,'L5GAN','corlayer5forM5','cor_wight')\n",
    "#MLGANcorL5M5.save_weights(corlayer5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLGANmodel_demo = MLGAN_L5.MLGAN(MLGANcorL1M5,MLGANcorL2M5,MLGANcorL3M5,MLGANcorL4M5,MLGANcorL5M5)#MLGAN layer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "inptest = next(iter(layer5dataforM5))\n",
    "MLGANmodel_demo(inptest,env.ADJMatrix)*datastd+datamean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe58164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
